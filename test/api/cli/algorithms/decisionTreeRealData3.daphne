#-------------------------------------------------------------
#
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.
#
# Modifications 2024 The DAPHNE Consortium.
#
#-------------------------------------------------------------

# This script has been manually translated from Apache SystemDS.

# For the Wine dataset.

import "../../../../scripts/algorithms/decisionTree.daph";
import "../../../../scripts/algorithms/decisionTreePredict.daph";
import "../../../../scripts/algorithms/lmPredictStats_.daph";

F = readFrame($data);

recoded12, dict12 = recode(as.matrix(F[, 12]), false);
X = cbind(cbind(cbind(cbind(cbind(cbind(cbind(cbind(cbind(cbind(cbind(cbind(
    bin(as.matrix(F[,  0]), 10)+1,
    bin(as.matrix(F[,  1]), 10)+1),
    bin(as.matrix(F[,  2]), 10)+1),
    bin(as.matrix(F[,  3]), 10)+1),
    bin(as.matrix(F[,  4]), 10)+1),
    bin(as.matrix(F[,  5]), 10)+1),
    bin(as.matrix(F[,  6]), 10)+1),
    bin(as.matrix(F[,  7]), 10)+1),
    bin(as.matrix(F[,  8]), 10)+1),
    bin(as.matrix(F[,  9]), 10)+1),
    bin(as.matrix(F[, 10]), 50)+1),
    bin(as.matrix(F[, 11]), 10)+1),
    recoded12+1
);

R = reshape(as.f64([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1]), 1, 13);

# TODO Remove reshape, only done to force copying of view data to fresh data object due to rowSkip-unaware kernels.
Y = reshape(X[, ncol(X) - 2], nrow(X), 1);
X = cbind(X[, 0:ncol(X) - 2], X[, ncol(X) - 1]);
X = replace(X, nan, 5); # 1 val

# TODO Seems like write is not rowSkip-awar: bug.
# TODO generally double-check all kernels for rowSkip-aware,

# TODO Support random forests.
#if( $dt==1 ) {
  # TODO Don't use 2 insted of "rss".
  M = decisionTree.decisionTree(/*X=*/X, /*y=*/Y, /*ctypes=*/R,
    /*max_depth=*/10, /*min_leaf=*/4, /*min_split=*/10,
    /*max_features=*/1.0, /*max_values=*/$maxV,
    /*impurity=*//*"rss"*/2, /*seed=*/7, /*verbose=*/false);
  yhat = decisionTreePredict.decisionTreePredict(/*X=*/X, /*y=*/Y, /*ctypes=*/R, /*M=*/M, /*strategy=*/0, /*verbose=*/false);
#}
#else {
#  sf = 1.0/($3-1);
#  M = randomForest(X=X, y=Y, ctypes=R, sample_frac=sf, num_trees=$3-1,
#        impurity="rss", max_features=1, max_values=$4,
#        min_split=10, min_leaf=4, seed=7, verbose=TRUE);
#  yhat = randomForestPredict(X=X, ctypes=R,  M=M)
#}

mn = aggMin(as.matrix<f64>(F[,ncol(F) - 2]));
mx = aggMax(as.matrix<f64>(F[,ncol(F) - 2]));
w = (mx - mn) / 10;
yhat2 = mn + (yhat - 1 + 0.5) * w;

R = lmPredictStats_.lmPredictStats(yhat2, as.matrix<f64>(F[,ncol(F) - 2]), false, false);
acc = as.scalar(R[2,]);
print(acc);